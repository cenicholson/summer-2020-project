{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ditchley S2DS project August 2020 - Code Pipeline<h1>\n",
    "    <h2>Team: Adam Hawken, Luca Lamoni, Elizabeth Nicholson, Robert Webster<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#![]() #graphical representation of the pipeline here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 0: Working directory and graph DB setup<h3>\n",
    "    <h4>0.1: Modules and working directory setup<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory & sub-directories already exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# Import modules and set up working directory\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "import csv\n",
    "import threading\n",
    "import queue\n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import twint\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Set up working directory\n",
    "# The working directory should reflect the structure of the Github repository https://github.com/S2DSLondon/Aug20_Ditchley\n",
    "sys.path.insert(1, 'C:/Users/Luca/Aug20_Ditchley/')\n",
    "from src.data import pipeline_setup\n",
    "pipeline_setup.build_data_dir('C:/Users/Luca/Aug20_Ditchley/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>0.2: Initialize graph database<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "from src.data import graphdb as gdb\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)\n",
    "graph\n",
    "# start with an empty graph\n",
    "graph.delete_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 1: Getting journalist twitter handles according to a keyword<h3>\n",
    "    <h4>The journalist scraping is performed at the web address https://www.journalism.co.uk/prof/?chunk=0&cmd=default<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose keyword and run the scraping function\n",
    "from src.data import journalists as journos\n",
    "keyword = 'cybersecurity'\n",
    "# Input: string / Output: list\n",
    "journo_handles = journos.get_handles_by_keyword(keyword)\n",
    "print(len(journo_handles))\n",
    "type(journo_handles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 2. Scrape user information and friend lists for each journalist in the list<h3>\n",
    "    <h4>2.1: Scrape user information using the Twitter API<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load twitter API credentials and return a tweepy API instance\n",
    "import json\n",
    "import tweepy\n",
    "from src.data import api_tweepy as api\n",
    "\n",
    "# Input: path of json file with credentials / Output: tweepy.api.API\n",
    "tw_api = api.connect_API('../src/data/twitter_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_friends_n</th>\n",
       "      <th>user_followers_n</th>\n",
       "      <th>prof_created_at</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>London</td>\n",
       "      <td>Editor of and digital magazines Verdict Magazi...</td>\n",
       "      <td>513</td>\n",
       "      <td>646</td>\n",
       "      <td>2011-07-15 06:29:08</td>\n",
       "      <td>2150</td>\n",
       "      <td>False</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>964233746865119233</td>\n",
       "      <td>jesscahaworth</td>\n",
       "      <td>Jessica Haworth</td>\n",
       "      <td></td>\n",
       "      <td>Cybersecurity journalist at Music buff and ski...</td>\n",
       "      <td>970</td>\n",
       "      <td>670</td>\n",
       "      <td>2018-02-15 20:23:34</td>\n",
       "      <td>453</td>\n",
       "      <td>False</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1186245031507693574</td>\n",
       "      <td>ad_nauseum74</td>\n",
       "      <td>Adam Bannister</td>\n",
       "      <td></td>\n",
       "      <td>Journalist The Daily Swig Cybersecurity</td>\n",
       "      <td>366</td>\n",
       "      <td>133</td>\n",
       "      <td>2019-10-21 11:38:12</td>\n",
       "      <td>112</td>\n",
       "      <td>False</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user_id    screen_name             name location  \\\n",
       "0            335773502    _lucyingham      Lucy Ingham   London   \n",
       "1   964233746865119233  jesscahaworth  Jessica Haworth            \n",
       "2  1186245031507693574   ad_nauseum74   Adam Bannister            \n",
       "\n",
       "                                    user_description  user_friends_n  \\\n",
       "0  Editor of and digital magazines Verdict Magazi...             513   \n",
       "1  Cybersecurity journalist at Music buff and ski...             970   \n",
       "2            Journalist The Daily Swig Cybersecurity             366   \n",
       "\n",
       "   user_followers_n     prof_created_at  favourites_count  verified  \\\n",
       "0               646 2011-07-15 06:29:08              2150     False   \n",
       "1               670 2018-02-15 20:23:34               453     False   \n",
       "2               133 2019-10-21 11:38:12               112     False   \n",
       "\n",
       "   statuses_count  \n",
       "0             452  \n",
       "1             576  \n",
       "2             277  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape user information using the API\n",
    "from src.data import api_user_tools as api_tools\n",
    "from src.data import data_cleanup as dc\n",
    "\n",
    "# Input: tweepy.api.API,list / Output: list\n",
    "api_users = api_tools.batch_request_user_info(tw_api,journo_handles)\n",
    "# Input: list / Output: DataFrame\n",
    "df_api = dc.populate_user_df(api_users)\n",
    "# Check\n",
    "df_api.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as csv\n",
    "df_api.to_csv('../data/processed/'+keyword+'_user_profiles.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.2: Load user info into graph DB<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in user information and drawing (Person) nodes\n"
     ]
    }
   ],
   "source": [
    "# Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to go around this problem on Windows machines it is\n",
    "# possible to create a shortcut between the two folders\n",
    "\n",
    "# lowd in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'cybersecurity_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.3: Scrape user friend list using Twint<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 to get friends of @_lucyinghamAttempt #1 to get friends of @JesscaHaworth\n",
      "Attempt #1 to get friends of @Ad_Nauseum74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #2 to get friends of @_lucyingham\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @Ad_Nauseum74 saved to: ../data/raw/cybersecurity_friends_Ad_Nauseum74.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @_lucyingham saved to: ../data/raw/cybersecurity_friends__lucyingham.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.feed:Follow:IndexError\n",
      "CRITICAL:root:twint.feed:Follow:IndexError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @JesscaHaworth saved to: ../data/raw/cybersecurity_friends_JesscaHaworth.csv\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from src.data import twint_tools as tt\n",
    "\n",
    "# define keyword arguments / 'n_retries' = max number of scrape attempts, 'suppress' = hide critical Twint warnings\n",
    "kwargs = {'n_retries':5,\n",
    "         'suppress':False}\n",
    "# Multi threading function Input: _get_friends function, number of threads to distribute the queque, args and kwargs\n",
    "tt.twint_in_queue(tt._get_friends, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@_lucyingham follows 513 users.\n",
      "@JesscaHaworth follows 970 users.\n",
      "@Ad_Nauseum74 follows 366 users.\n",
      "\n",
      "Total number of handles pulled: 1849\n",
      "Number of unique twitter handles: 1709\n",
      "\n",
      "Zero following in list for users: []\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all the individual lists into one dataframe with journalist and its friends\n",
    "friends_csv = tt.join_friends_csv(journo_handles,keyword) # this function has a bug, the first friend name is 'username'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe as csv\n",
    "friends_csv.to_csv('../data/processed/'+keyword+'_journalist_friends.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>2.4: Load friend information into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading in friends info and drawing [FOLLOWS] edges\n"
     ]
    }
   ],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'cybersecurity_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 3. Loop over selected journalists handles and scrape their tweets (3.1) and mentions (3.2) using Twint<h3>\n",
    "    <h4>Section 3.1: Scrape tweets using Twint<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt #1 to get tweets of @_lucyingham\n",
      "Attempt #1 to get tweets of @JesscaHaworthAttempt #1 to get tweets of @Ad_Nauseum74\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n",
      "CRITICAL:root:twint.get:User:'NoneType' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for @Ad_Nauseum74 saved to: ../data/raw/cybersecurity_tweets_Ad_Nauseum74.csv\n",
      "Results for @JesscaHaworth saved to: ../data/raw/cybersecurity_tweets_JesscaHaworth.csv\n",
      "Results for @_lucyingham saved to: ../data/raw/cybersecurity_tweets__lucyingham.csv\n"
     ]
    }
   ],
   "source": [
    "from src.data import twint_tools as tt\n",
    "# define keyword arguments\n",
    "kwargs = {'date_range':('2020-08-01 00:00:00', None),\n",
    "         'n_retries':5,\n",
    "         'suppress':False}\n",
    "# multi threading\n",
    "tt.twint_in_queue(tt._search_tweets_by_user, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>timezone</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>name</th>\n",
       "      <th>place</th>\n",
       "      <th>...</th>\n",
       "      <th>geo</th>\n",
       "      <th>source</th>\n",
       "      <th>user_rt_id</th>\n",
       "      <th>user_rt</th>\n",
       "      <th>retweet_id</th>\n",
       "      <th>reply_to</th>\n",
       "      <th>retweet_date</th>\n",
       "      <th>translate</th>\n",
       "      <th>trans_src</th>\n",
       "      <th>trans_dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298141120128524288</td>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>1598335935000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>08:12:15</td>\n",
       "      <td>Romance Daylight Time</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298136447258697728</td>\n",
       "      <td>1298131556251262976</td>\n",
       "      <td>1598334821000</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>07:53:41</td>\n",
       "      <td>Romance Daylight Time</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298015000519487490</td>\n",
       "      <td>1298001949468524549</td>\n",
       "      <td>1598305866000</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>23:51:06</td>\n",
       "      <td>Romance Daylight Time</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298012906626392067</td>\n",
       "      <td>1298001949468524549</td>\n",
       "      <td>1598305367000</td>\n",
       "      <td>2020-08-24</td>\n",
       "      <td>23:42:47</td>\n",
       "      <td>Romance Daylight Time</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1296054092234719233</td>\n",
       "      <td>1296054092234719233</td>\n",
       "      <td>1597838349000</td>\n",
       "      <td>2020-08-19</td>\n",
       "      <td>13:59:09</td>\n",
       "      <td>Romance Daylight Time</td>\n",
       "      <td>335773502</td>\n",
       "      <td>_lucyingham</td>\n",
       "      <td>Lucy Ingham</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'user_id': '335773502', 'username': '_lucyin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id      conversation_id     created_at        date  \\\n",
       "0  1298141120128524288  1298131556251262976  1598335935000  2020-08-25   \n",
       "1  1298136447258697728  1298131556251262976  1598334821000  2020-08-25   \n",
       "2  1298015000519487490  1298001949468524549  1598305866000  2020-08-24   \n",
       "3  1298012906626392067  1298001949468524549  1598305367000  2020-08-24   \n",
       "4  1296054092234719233  1296054092234719233  1597838349000  2020-08-19   \n",
       "\n",
       "       time               timezone    user_id     username         name  \\\n",
       "0  08:12:15  Romance Daylight Time  335773502  _lucyingham  Lucy Ingham   \n",
       "1  07:53:41  Romance Daylight Time  335773502  _lucyingham  Lucy Ingham   \n",
       "2  23:51:06  Romance Daylight Time  335773502  _lucyingham  Lucy Ingham   \n",
       "3  23:42:47  Romance Daylight Time  335773502  _lucyingham  Lucy Ingham   \n",
       "4  13:59:09  Romance Daylight Time  335773502  _lucyingham  Lucy Ingham   \n",
       "\n",
       "   place  ... geo source user_rt_id user_rt  retweet_id  \\\n",
       "0    NaN  ... NaN    NaN        NaN     NaN         NaN   \n",
       "1    NaN  ... NaN    NaN        NaN     NaN         NaN   \n",
       "2    NaN  ... NaN    NaN        NaN     NaN         NaN   \n",
       "3    NaN  ... NaN    NaN        NaN     NaN         NaN   \n",
       "4    NaN  ... NaN    NaN        NaN     NaN         NaN   \n",
       "\n",
       "                                            reply_to  retweet_date translate  \\\n",
       "0  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "1  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "2  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "3  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "4  [{'user_id': '335773502', 'username': '_lucyin...           NaN       NaN   \n",
       "\n",
       "  trans_src trans_dest  \n",
       "0       NaN        NaN  \n",
       "1       NaN        NaN  \n",
       "2       NaN        NaN  \n",
       "3       NaN        NaN  \n",
       "4       NaN        NaN  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joined all the individual csv into one dataframe\n",
    "cyber_test = tt.join_tweet_csv(journo_handles, keyword)\n",
    "# Check\n",
    "cyber_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as csv\n",
    "cyber_test.to_csv('../data/processed/'+keyword+'_journalist_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 3.2: Extract mentions from Twint dataset<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1298141120128524288</td>\n",
       "      <td>delafina777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1298136447258697728</td>\n",
       "      <td>delafina777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1298015000519487490</td>\n",
       "      <td>berenicejbaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1298012906626392067</td>\n",
       "      <td>berenicejbaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295467814304849920</td>\n",
       "      <td>journalists4bel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id         mentions\n",
       "0  1298141120128524288      delafina777\n",
       "1  1298136447258697728      delafina777\n",
       "2  1298015000519487490   berenicejbaker\n",
       "3  1298012906626392067   berenicejbaker\n",
       "4  1295467814304849920  journalists4bel"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data import data_cleanup as dc\n",
    "# from the twint dataset, extract mentions based on tweet id and save in a separate csv\n",
    "mentions_twint  = dc.twint_mentions_to_df(cyber_test)\n",
    "# Check\n",
    "mentions_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "mentions_twint.to_csv('../data/processed/' + keyword + '_mentions_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 4. Loop over selected journalists handles and scrape their tweets (4.1) and mentions (4.2) using Twitter API<h3>\n",
    "    <h4>Section 4.1: Scrape tweets using Twint ################ I am waiting for Rob function here<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from src.data import api_tweepy as api\n",
    "#Load twitter API credentials and return a tweepy API instance\n",
    "tw_api = api.connect_API('../src/data/twitter_credentials.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 4.2: Extract mentions from API tweets<h4> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 5. Data cleaning and standardization/LDA<h3>\n",
    "     <h4>Section 5.1: Clean and standardize Twint dataset<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the twint output \n",
    "from src.data import data_cleanup as dc\n",
    "#Create the standardized template\n",
    "test_twint = dc.standard_tweet_dataset_setup()\n",
    "test_twint\n",
    "#fill the template\n",
    "standard_tweet_twint = dc.fill_standard_tweet_dataset_with_twint(test_twint, cyber_test)\n",
    "# Check\n",
    "standard_tweet_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "standard_tweet_twint.to_csv('../data/processed/' + keyword + '_standard_tweets_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 5.2: Clean and standardize API dataset<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add here new cleaning function Rob is working on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 6. Create graph database and import twitter data into it<h3>\n",
    "    <h4>Section 6.1: Import modules and load graph database<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from py2neo import Graph\n",
    "from py2neo.data import Node, Relationship\n",
    "from src.data import graphdb as gdb\n",
    "\n",
    "# load / declare the database\n",
    "graph = gdb.get_graph(new_graph = True)\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.2: Load user info into graph DB<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neo4j import files need to be in a specific folder, however, the csv files saved above are in a different folder, to go around this problem on Windows machines it is\n",
    "# possible to create a shortcut between the two folders\n",
    "\n",
    "# lowd in user information\n",
    "print('Loading in user information and drawing (Person) nodes')\n",
    "fn_users = 'cybersecurity_user_profiles.csv'\n",
    "gdb.load_users(fn_users ,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.2: Load friend information into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in friend information\n",
    "print('Loading in friends info and drawing [FOLLOWS] edges')\n",
    "fn_friends = 'cybersecurity_journalist_friends.csv'\n",
    "gdb.load_friends(fn_friends,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.3: Load tweet data into DB<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tweet information\n",
    "print('Loading in tweets and drawing (Tweet) nodes')\n",
    "fn_tweets = '/data/processed/cybersecurity_standard_tweets_twint.csv'\n",
    "gdb.load_tweets(fn_tweets ,graph) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.4: Draw edges between users and their tweets<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw edges between users and their tweets\n",
    "print('Drawing [POSTS] edges')\n",
    "gdb.get_posts(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.5: Load tweets' mentions<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in mentions information\n",
    "print('Loading in mentions and drawing [MENTIONS] edges')\n",
    "fn_mentions = 'cybersecurity_mentions_twint.csv'\n",
    "gdb.load_mentions(fn_mentions,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.6: Run page rank algorithm using [FOLLOWS] [MENTIONS] edges<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run Page rank using follower and mention edges\n",
    "print('running page rank')\n",
    "nodelist = ['Person','Tweet']\n",
    "edgelist = ['FOLLOWS','MENTIONS']\n",
    "page_rank_friends_mentions = gdb.run_pagerank(nodelist,edgelist,graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 6.7: Get a weighted random sample from the journalists friends<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a weighted random sample of users\n",
    "n_sample = 20\n",
    "fields = ['rank']\n",
    "exponents = [2]\n",
    "sample = gdb.get_multiple_weighted_sample(page_rank_friends_mentions,n_sample,fields,exponents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
