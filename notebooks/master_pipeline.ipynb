{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Ditchley S2DS project August 2020 - Code Pipeline<h1>\n",
    "    <h2>Team: Adam Hawken, Luca Lamoni, Elizabeth Nicholson, Robert Webster<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules and set up working directory\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "import json\n",
    "import csv\n",
    "import threading\n",
    "import queue\n",
    "import asyncio \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "import twint\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(1, 'C:/Users/Luca/Aug20_Ditchley')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 1: Getting journalist twitter handles according to a keyword<h3>\n",
    "    <h4>The journalist scraping is performed at the web address https://www.journalism.co.uk/prof/?chunk=0&cmd=default<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from src.data import journalists as journos\n",
    "keyword = 'cybersecurity'\n",
    "journo_handles = journos.get_handles_by_keyword(keyword)\n",
    "print(len(journo_handles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 2. Loop over selected journalists handles and download their tweets<h3>\n",
    "    <h4>Section 2.1: Download tweets using Twint<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import twint_tools as tt\n",
    "# define keyword arguments\n",
    "kwargs = {'date_range':('2020-08-01 00:00:00', None),\n",
    "         'n_retries':5,\n",
    "         'suppress':False}\n",
    "# multi threading\n",
    "tt.twint_in_queue(tt._search_tweets_by_user, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joined all the individual csv into one dataframe\n",
    "cyber_test = tt.join_tweet_csv(journo_handles, keyword)\n",
    "# Check\n",
    "cyber_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise the twint output \n",
    "from src.data import data_cleanup as dc\n",
    "#Create the standardized template\n",
    "test_twint = dc.standard_tweet_dataset_setup('test_twint')\n",
    "test_twint\n",
    "#fill the template\n",
    "standard_tweet_twint = dc.fill_standard_tweet_dataset_with_twint(test_twint, cyber_test)\n",
    "# Check\n",
    "standard_tweet_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "standard_tweet_twint.to_csv('../data/processed/' + keyword + '_standard_tweets_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 2.2: Extract mentions from Twint dataset<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the twint dataset, extract mentions based on tweet id and save in a separate csv\n",
    "mentions_twint  = dc.twint_mentions_to_df(cyber_test)\n",
    "# Check\n",
    "mentions_twint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "mentions_twint.to_csv('../data/processed/' + keyword + '_mentions_twint.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 2.3: Scrape list of friends for each journalist<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import twint_tools as tt\n",
    "# define keyword arguments\n",
    "kwargs = {#'date_range':('2020-08-01 00:00:00', None),\n",
    "         'n_retries':5,\n",
    "         'suppress':False}\n",
    "# multi threading\n",
    "tt.twint_in_queue(tt._get_friends, 3, journo_handles, args=('../data/raw/'+keyword+'_',), kwargs=kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the individual lists into one dataframe with journalist and its friends\n",
    "friends_csv = tt.join_friends_csv(journo_handles,keyword) # this function has a bug, the first friend name is 'username'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe\n",
    "friends_csv.to_csv('../data/raw/'+keyword+'_journalist_friends.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 2.4: Scrape for each journalist the user information using Twitter API<h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "from src.data import api_tweepy as api\n",
    "#Load twitter API credentials and return a tweepy API instance\n",
    "tw_api = api.connect_API('../src/data/twitter_credentials.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "batch_pull_user_info() missing 1 required positional argument: 'kwargs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-736483c65b18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Scrape user information using the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapi_user_tools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mapi_tools\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mapi_users\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapi_tools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_pull_user_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtw_api\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjourno_handles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: batch_pull_user_info() missing 1 required positional argument: 'kwargs'"
     ]
    }
   ],
   "source": [
    "# Scrape user information using the API\n",
    "from src.data import api_user_tools as api_tools\n",
    "api_users = api_tools.batch_pull_user_info(tw_api,journo_handles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Section 2b: Download tweets using API<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Section 3. Loop over selected journalists handles and download their lists of friends<h3>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
